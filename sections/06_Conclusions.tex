\section{Conclusions, Limitations and Future Work}
We studied the problem of fine-tune pre-trained generative policies with \ac{rl} while preserving multimodal action distributions. Focusing on diffusion policies trained from demonstrations, we showed that standard fine-tuning often collapsed multimodality to a dominant behavior when the fine-tuning reward landscape diverged from the demonstrations. To address this, we proposed using mutual information as a proxy for multimodality and introduced MD\textendash MAD, an unsupervised mode-discovery method based on a latent reparameterization of a steering policy. We then used the steering policy together with the mutual-information estimate to provide an intrinsic reward that regularized \ac{rl} fine-tuning toward retaining diverse behaviors.  We benchmarked the method across different robotics environments, and showcased that the proposed regularization mitigated mode collapse, supporting MD\textendash MAD as a practical approach to fine-tuning generative policies without sacrificing behavioral diversity.


\paragraph{Limitations and Future Work.} Our study revealed several trade-offs and open directions. The intrinsic-reward regularization required careful tuning, as excessive weight slowed learning and reduced task success. Maintaining an inference model during fine-tuning also introduced instabilities, as it needed to track the policy’s shifting state distribution. 
\reb{Moreover, in its current form, MD-MAD is designed as a task-level mode extractor, as it focuses on discovering and preserving \emph{within-task} behavioral modes, rather than modeling the structure of multi-task datasets. 
Therefore, scaling MD-MAD to large, heterogeneous datasets may require richer latent parametrizations, such as a hierarchical latent space, to capture multi-task-level multimodality. %Real-world applicability also remains to be evaluated.

Designing the appropriate parametrization and structure of the latent space is also challenging.  In all experiments, we employed a single categorical latent $\mathcal{Z}$ indexing discrete behavioral modes within each task. We deliberately used a mildly overparameterized space, and our results indicated that MD-MAD could reliably collapse redundant codes and recover the relevant modes, suggesting that overparameterization is not critical in practice. 
Nonetheless, exploring more expressive continuous or hybrid latent spaces, together with regularization strategies that improve the controllability of $\mathcal{Z}$, such as entropy or KL terms to balance code usage and mitigate mode collapse, is an important direction for future work. %Nonetheless, exploring more expressive continuous or hybrid latent spaces, possibly combined with regularization strategies enhancing the controllability of $\mathcal{Z}$, for instance via entropy/KL regularization to encourage balanced use of codes or more structured (e.g., factorized or hierarchical) latents, is an important direction for future work.


% Exploring more expressive continuous or hybrid latent spaces, possibly combined with regularization strategies from recent skill-discovery methods to represent richer or unbounded behavioral diversity, is an important avenue for future work.
} 




% One of the major failure cases of our proposed method was the inability to retain all modalities in the \emph{Avoid} environment. We hypothesize that using a single latent per trajectory limited adaptation when multimodality emerged late in an episode and could be addressed with hierarchical or time-varying latents that permit mode switches within a rollout. \reb{More generally, our formulation currently introduces $\mathcal{Z}$ as a single categorical index that governs the diffusion noise $\mathcal{W}$; this avoids trivial autoencoding of $\mathcal{W}$ but does not preclude degeneracies in which multiple $z$-values collapse to the same behavior. Such mode collapse is partly due to known limitations of mutual-information-based diversity objectives and we do observe it in some settings. A straightforward extension is to add a KL or entropy regularization term that encourages the inferred posterior $q_\phi(z \mid \tau)$ to match a uniform prior, promoting balanced, controllable usage of all codes. Stronger notions of semantic controllability—such as enforcing independence or disentanglement across latent components via TC-style regularizers—would require extending $\mathcal{Z}$ to a factorized or hierarchical discrete structure, which we leave for future work.} 

% A second failure case arose with highly stochastic action generation (e.g.\, DDPM sampling), where mapping modes to input noise for maximizing mutual information was hindered by the sampling stochasticity, reducing the ability to steer the policy towards consistent behaviors. \reb{This highlights that our current diversity regularizer primarily evaluates trajectory-level consistency under fixed sampling procedures and may be brittle when the diffusion sampling noise dominates the controllable signal in $\mathcal{W}$.} Exploring stage-aware steering at later diffusion steps or adaptive noise schedules may help mitigate this limitation. 
\reb{

% We occasionally observed that distinct latent codes were mapped to the same environment-defined mode, indicating that our mutual-information objective can be sensitive to small variations in the visited state distribution. Accordingly, this work should be regarded as an initial feasibility study of using diversity regularization to preserve multimodality during fine-tuning, and systematically assessing which trajectory-diversity metrics most effectively retain multimodal behavior is a promising direction for future work.
We occasionally observed that distinct latent codes were mapped to the same environment-defined mode, indicating that our mutual information objective can be sensitive to small variations in the visited state distribution. This is a known weakness of mutual information-based unsupervised skill discovery illustrated in~\cite{CSD}, and systematically assessing which trajectory-diversity metrics most effectively retain multimodal behavior is a promising direction for future work.}

% \paragraph{Limitations and Future Work.}
% \reb{In this work, MD-MAD is used as an action-level, task-conditioned mode extractor that focuses on within-task behavioral modes; extending it to large, heterogeneous multi-task datasets will likely require hierarchical or structured latent spaces that separate dataset- or task-level variation from task-specific behaviors. We currently employ a single categorical latent $\mathcal{Z}$ with mildly overparameterized cardinality: while this is sufficient to recover the relevant modes in our experiments, mutual-information-based training can still collapse different codes to similar behaviors. Improving the semantic controllability of $\mathcal{Z}$—for example via entropy/KL regularization towards a uniform prior, or by moving to factorized or hierarchical (possibly continuous or hybrid) latent parametrizations with disentanglement objectives—is an interesting direction that we leave for future work.}

% One of the major failure cases of our proposed method was the inability to retain all modalities in the \emph{Avoid} environment. We hypothesize that using a single latent per trajectory limited adaptation when multimodality emerged late in an episode and could be addressed with hierarchical or time-varying latents that permit mode switches within a rollout. A second failure case arose with highly stochastic action generation (e.g.\, DDPM sampling), where mapping modes to input noise for maximizing mutual information was hindered by the sampling stochasticity, reducing the ability to steer the policy towards consistent behaviors. Exploring stage-aware steering at later diffusion steps or adaptive noise schedules may help mitigate this limitation.


Finally, although the formulation was independent of language supervision, the learned latent space is amenable to post-hoc semantic grounding. Aligning modes with language via preference learning or VLA mappings and developing a joint inference model that preserves diversity while enabling reliable semantic labels are compelling directions for future work.


\section*{Reproducibility Statement}

We have made extensive efforts to ensure the reproducibility of our results. All algorithmic details, including model architectures, training procedures, and hyperparameters, are described in the main text and appendix. If any hyperparameter is not explicitly documented in the paper, it will be fully specified in the released code repository. Upon acceptance, we will release the complete codebase, together with configuration files, pretrained checkpoints, and evaluation scripts, to allow exact replication of our experiments. Additionally, proofs of theoretical claims and ablation studies supporting our design choices are included in the appendix.